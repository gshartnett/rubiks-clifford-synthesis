{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- simple article: https://www.geeksforgeeks.org/introduction-to-beam-search-algorithm/\n",
    "- many beam search descriptions are given in terms of NLP context\n",
    "- I think A* might not be feasible for large graphs, but I'm not sure...\n",
    "- It'd be nice to code up the Clifford problem in a nice object-oriented with that made the graph structure abstracted, so I could use any old graph traversal algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import rubiks.clifford as cl\n",
    "import rubiks.lgf as lgf\n",
    "from qiskit.quantum_info import Clifford\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_qubits = 6\n",
    "\n",
    "SEED = 123\n",
    "use_qiskit = False\n",
    "device = torch.device('cpu')\n",
    "drop_phase_bits = True\n",
    "scaling = 'log-linear'\n",
    "data_dir = f\"data/data_n_{num_qubits}_drop_phase_bits_scaling_{scaling}/\"\n",
    "high = cl.max_random_sequence_length(num_qubits, scaling)\n",
    "\n",
    "lgf_model = lgf.LGFModel(\n",
    "    num_qubits=num_qubits,\n",
    "    device=device,\n",
    "    rng=np.random.default_rng(SEED),\n",
    "    hidden_layers=[32, 16, 4, 2],\n",
    "    drop_phase_bits=drop_phase_bits,\n",
    "    use_qiskit=use_qiskit,\n",
    ").to(device)\n",
    "\n",
    "lgf_model.load_state_dict(torch.load(data_dir + \"checkpoint\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Put this in the same format as other hillclimbing function\n",
    "- Compare for different values of beam_width\n",
    "    - should agree with previous results for beam_width=1\n",
    "    - should be better for larger beam_widths\n",
    "- Can it be made faster?\n",
    "- Could add more tests\n",
    "    - loading a Clifford from a bitstring\n",
    "    - printing bitstring from Clifford\n",
    "- Check that the final move_history is indeed a solution before exiting\n",
    "- check hillclimbing/beamsearch for dropping phase bits and not dropping them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found after 5 steps\n",
      "[(3, 5, 'swap'), (0, 4, 'swap'), (1, 'sdg'), (0, 1, 'cx'), (5, 'h')]\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 15\n",
    "initial_sequence = cl.random_sequence(np.random.default_rng(), seq_length=sequence_length, num_qubits=num_qubits)\n",
    "initial_state = cl.sequence_to_tableau(initial_sequence, num_qubits)\n",
    "results_dict = lgf.beam_search(initial_state=initial_state, lgf_model=lgf_model, beam_width=5, max_iter=1000, drop_phase_bits=True)\n",
    "\n",
    "count = results_dict['count']\n",
    "success = results_dict['success']\n",
    "\n",
    "if success is False:\n",
    "    print(f\"No solution found after {count+1} steps\")\n",
    "else:\n",
    "    print(f\"Solution found after {count+1} steps\")\n",
    "    print(results_dict['move_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = initial_state @ cl.sequence_to_tableau(results_dict['move_history'], num_qubits=num_qubits)\n",
    "np.array_equal(state.tableau[:,:-1], cl.sequence_to_tableau([], num_qubits=num_qubits).tableau[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found solution in 5 steps\n",
      "[(3, 5, 'swap'), (0, 4, 'swap'), (1, 'sdg'), (0, 1, 'cx'), (5, 'h')]\n"
     ]
    }
   ],
   "source": [
    "results_dict_hillclimbing = lgf.hillclimbing(initial_state=initial_state, lgf_model=lgf_model, max_iter=1000)\n",
    "if results_dict_hillclimbing['success']:\n",
    "    print(f\"found solution in {len(results_dict_hillclimbing['move_history'])} steps\")\n",
    "    print(results_dict_hillclimbing['move_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = initial_state @ cl.sequence_to_tableau(results_dict_hillclimbing['move_history'], num_qubits=num_qubits)\n",
    "np.array_equal(state.tableau[:,:-1], cl.sequence_to_tableau([], num_qubits=num_qubits).tableau[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the move history to be in the same format\n",
    "state = initial_state @ cl.sequence_to_tableau(results_dict_hillclimbing['move_history'][::-1], num_qubits=num_qubits)\n",
    "state == cl.sequence_to_tableau([], num_qubits=num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run('lgf.beam_search(initial_state=initial_state, lgf_model=lgf_model, beam_width=5, max_iter=1000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rubiks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
